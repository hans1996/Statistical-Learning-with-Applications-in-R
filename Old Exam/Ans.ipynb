{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "### (a). \n",
    "The fitted model will be\n",
    "\n",
    "$$-17.2014*(Intercept)-0.0075*displacement+0.0316*horsepower-0.0069*weight+0.1022*acceleration+0.7586*year$$  \n",
    "\n",
    "The taining error is  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "10.9626113523895"
      ],
      "text/latex": [
       "10.9626113523895"
      ],
      "text/markdown": [
       "10.9626113523895"
      ],
      "text/plain": [
       "[1] 10.96261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Auto_train=read.csv(\"./Data/auto/auto_train.csv\",header = T)\n",
    "Auto_test=read.csv(\"./Data/auto/auto_test.csv\",header = T)\n",
    "m1=lm(mpg~.,data=Auto_train)\n",
    "mean((Auto_train$mpg-m1$fitted.values)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "12.7836089032359"
      ],
      "text/latex": [
       "12.7836089032359"
      ],
      "text/markdown": [
       "12.7836089032359"
      ],
      "text/plain": [
       "[1] 12.78361"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_y=predict(m1,newdata = Auto_test)\n",
    "mean((Auto_test$mpg-pred_test_y)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model using predictors which are statically signicant will be  \n",
    "\n",
    "$$-12.667*(Intercept)-0.0066*weight+0.7347*year$$  \n",
    "\n",
    "The taining error is  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "11.1601312696737"
      ],
      "text/latex": [
       "11.1601312696737"
      ],
      "text/markdown": [
       "11.1601312696737"
      ],
      "text/plain": [
       "[1] 11.16013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m2=lm(mpg~weight+year,data=Auto_train)\n",
    "mean((Auto_train$mpg-m2$fitted.values)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "12.1659051153108"
      ],
      "text/latex": [
       "12.1659051153108"
      ],
      "text/markdown": [
       "12.1659051153108"
      ],
      "text/plain": [
       "[1] 12.16591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_y_2=predict(m2,newdata = Auto_test)\n",
    "mean((Auto_test$mpg-pred_test_y_2)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b). \n",
    "The fitted model of rigor regression will be \n",
    "\n",
    "$$-7.3884*(Intercept)-0.0178*displacement-0.0106*horsepower+-0.004*weight-0.13*acceleration+0.6509*year$$\n",
    "\n",
    "The taining error is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "11.5361177947091"
      ],
      "text/latex": [
       "11.5361177947091"
      ],
      "text/markdown": [
       "11.5361177947091"
      ],
      "text/plain": [
       "[1] 11.53612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(glmnet)\n",
    "set.seed(1)\n",
    "m3=cv.glmnet(as.matrix(Auto_train[,-1]),Auto_train[,1],alpha=0,family=\"gaussian\")\n",
    "pred_train_rigor=predict(m3,s=m3$lambda.min,newx = as.matrix(Auto_train[,-1]))\n",
    "mean((Auto_train$mpg-pred_train_rigor)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "13.1234258239398"
      ],
      "text/latex": [
       "13.1234258239398"
      ],
      "text/markdown": [
       "13.1234258239398"
      ],
      "text/plain": [
       "[1] 13.12343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_rigor=predict(m3,s=m3$lambda.min,newx = as.matrix(Auto_test[,-1]))\n",
    "mean((Auto_test$mpg-pred_test_rigor)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c). \n",
    "The fitted model of lasso regression will be \n",
    "\n",
    "$$-3.4811*(Intercept)-0.0039*displacement+0*horsepower-0.0055*weight+0*acceleration+0.5809*year$$\n",
    "\n",
    "The taining error is  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "11.1766362817694"
      ],
      "text/latex": [
       "11.1766362817694"
      ],
      "text/markdown": [
       "11.1766362817694"
      ],
      "text/plain": [
       "[1] 11.17664"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "m4=cv.glmnet(as.matrix(Auto_train[,-1]),Auto_train[,1],family=\"gaussian\")\n",
    "pred_train_lasso=predict(m4,s=m4$lambda.min,newx = as.matrix(Auto_train[,-1]))\n",
    "mean((Auto_train$mpg-pred_train_lasso)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error is  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "12.3069322538482"
      ],
      "text/latex": [
       "12.3069322538482"
      ],
      "text/markdown": [
       "12.3069322538482"
      ],
      "text/plain": [
       "[1] 12.30693"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_lasso=predict(m4,s=m4$lambda.min,newx = as.matrix(Auto_test[,-1]))\n",
    "mean((Auto_test$mpg-pred_test_lasso)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d). \n",
    "According to (a)-(c), multiple regression with significant variables has the smallest test error.\n",
    "\n",
    "\n",
    "### (e). \n",
    "Multiple regrssion bootstrap result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: boot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto_train, statistic = mul_coef, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "         original        bias    std. error\n",
       "t1* -17.201371221  0.2056591419 6.564682038\n",
       "t2*  -0.007486269 -0.0006769300 0.009319236\n",
       "t3*   0.031571242 -0.0009805104 0.016530374\n",
       "t4*  -0.006863507  0.0001041661 0.001170817\n",
       "t5*   0.102209315 -0.0094372236 0.187127444\n",
       "t6*   0.758614461 -0.0018574626 0.068721270"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(boot)\n",
    "mul_coef<-function(data,index)\n",
    "{\n",
    "  NewData=Auto_train[index,]\n",
    "  m1=lm(mpg~.,data=NewData)\n",
    "  summary(m1)\n",
    "  return(m1$coefficients)\n",
    "}\n",
    "boot(Auto_train,mul_coef,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rigor regrssion bootstrap result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto_train, statistic = rigor_coef, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "       original        bias     std. error\n",
       "t1* -7.44231850  1.445685e-01 5.4196139147\n",
       "t2* -0.01781736 -2.775356e-04 0.0035586663\n",
       "t3* -0.01034566 -9.335460e-04 0.0076225139\n",
       "t4* -0.00404830  5.084114e-05 0.0003849608\n",
       "t5* -0.12856090 -2.013515e-03 0.1281383001\n",
       "t6*  0.65120273 -1.795618e-03 0.0605157788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rigor_coef<-function(data,index)\n",
    "{\n",
    "  NewData=Auto_train[index,]\n",
    "  m3_new=glmnet(as.matrix(NewData[,-1]),NewData[,1],lambda=m3$lambda.min,alpha = 0,family=\"gaussian\");\n",
    "  return(as.vector(coef(m3_new)))\n",
    "}\n",
    "boot(Auto_train,rigor_coef,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lasso regrssion bootstrap result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto_train, statistic = lasso_coef, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "         original        bias     std. error\n",
       "t1* -10.688448694  2.924819e-01 5.3323317017\n",
       "t2*  -0.003747162 -2.517098e-03 0.0063875506\n",
       "t3*   0.000000000  6.094799e-05 0.0016033147\n",
       "t4*  -0.006071524  2.429621e-04 0.0007322893\n",
       "t5*   0.000000000 -2.023654e-02 0.0855149766\n",
       "t6*   0.696516494 -2.979130e-03 0.0650959365"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso_coef<-function(data,index)\n",
    "{\n",
    "  NewData=Auto_train[index,]\n",
    "  m4_new=glmnet(as.matrix(NewData[,-1]),NewData[,1],lambda=m4$lambda.min,alpha = 1,family=\"gaussian\");\n",
    "  return(as.vector(coef(m4_new)))\n",
    "}\n",
    "boot(Auto_train,lasso_coef,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For displacement, weight and year, rigor regression have lowest standard error. For horsepower and acceleration, lasso regression have lowest standard error. For horsepower and acceleration lasso will tends to zeros, so the standard error will lower than rigor regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "### (a). \n",
    "The smallest k will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>PC84:</strong> 84"
      ],
      "text/latex": [
       "\\textbf{PC84:} 84"
      ],
      "text/markdown": [
       "**PC84:** 84"
      ],
      "text/plain": [
       "PC84 \n",
       "  84 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_train=read.csv(\"./Data/digits/digits_train.csv\",header=T);\n",
    "A_test=read.csv(\"./Data/digits/digits_test.csv\",header=T);\n",
    "\n",
    "train_X=A_train[,-1];\n",
    "train_Y=A_train[,1];\n",
    "\n",
    "test_X=A_test[,-1];\n",
    "test_Y=A_test[,1];\n",
    "#(a)\n",
    "p1=prcomp(train_X);\n",
    "tmp=summary(p1);\n",
    "k=which(tmp$importance[3,]>=0.9)[1];\n",
    "k\n",
    "new_train_X=as.matrix(train_X)%*%tmp$rotation[,1:k];\n",
    "new_test_X=as.matrix(test_X)%*%tmp$rotation[,1:k];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b). \n",
    "Fit LDA models. The training classification error will be   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: MASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   train_Y\n",
       "      0   1   2   3   4   5   6   7   8   9\n",
       "  0 287   0   6   0   0   3   4   2   0   3\n",
       "  1   0 338   6   6   3   2   2   5  13   2\n",
       "  2   1   1 244   5   0   2   1   2   2   0\n",
       "  3   1   1   7 272   0  12   0   1   8   4\n",
       "  4   1   0   4   0 262   2  10   4   1  15\n",
       "  5   5   5   1  16   0 224  10   1  16   0\n",
       "  6   9   1   5   4   4   4 266   0   2   0\n",
       "  7   0   0   4   5   0   0   0 258   0   8\n",
       "  8   2   3  10   7   3   5   2   1 243   2\n",
       "  9   0   2   4   4  23  10   1  26   8 251"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.118333333333333"
      ],
      "text/latex": [
       "0.118333333333333"
      ],
      "text/markdown": [
       "0.118333333333333"
      ],
      "text/plain": [
       "[1] 0.1183333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(MASS)\n",
    "cm1=lda(train_Y~.,data=as.data.frame(new_train_X))\n",
    "lda.pred=predict(cm1 ,newdata=as.data.frame(new_train_X))\n",
    "table1=table(lda.pred$class,train_Y)\n",
    "table1\n",
    "1-sum(diag(table1))/sum(table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test classification error will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   test_Y\n",
       "      0   1   2   3   4   5   6   7   8   9\n",
       "  0 272   0   1   3   0   5   1   0   3   3\n",
       "  1   0 294   6   5   4   5   6   7  11   2\n",
       "  2   2   2 224  11   0   1   0   3   5   1\n",
       "  3   1   2   3 256   0  24   0   6  12   6\n",
       "  4   1   0   6   1 227   3   2   4   0  19\n",
       "  5  13   3   5  20   3 220   7   1  20   1\n",
       "  6   2   0  13   3   0   5 287   0   3   0\n",
       "  7   1   1  10   4   1   0   0 262   3   9\n",
       "  8   5  12   9   9   1   8   1   2 247   0\n",
       "  9   0   0   4   5  31   5   0  28   9 277"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.144666666666667"
      ],
      "text/latex": [
       "0.144666666666667"
      ],
      "text/markdown": [
       "0.144666666666667"
      ],
      "text/plain": [
       "[1] 0.1446667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda.pred.test=predict(cm1 ,newdata=as.data.frame(new_test_X))\n",
    "table2=table(lda.pred.test$class,test_Y)\n",
    "table2\n",
    "1-sum(diag(table2))/sum(table2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c). \n",
    "Fit QDA models. The training classification error will be   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   train_Y\n",
       "      0   1   2   3   4   5   6   7   8   9\n",
       "  0 306   0   0   0   0   0   0   0   0   0\n",
       "  1   0 348   0   0   0   0   0   0   1   0\n",
       "  2   0   1 291   1   0   0   0   0   0   0\n",
       "  3   0   0   0 316   0   0   0   0   0   1\n",
       "  4   0   1   0   0 295   0   0   0   0   2\n",
       "  5   0   0   0   1   0 264   0   0   0   0\n",
       "  6   0   1   0   0   0   0 296   0   0   0\n",
       "  7   0   0   0   0   0   0   0 299   0   1\n",
       "  8   0   0   0   1   0   0   0   1 292   0\n",
       "  9   0   0   0   0   0   0   0   0   0 281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.004"
      ],
      "text/latex": [
       "0.004"
      ],
      "text/markdown": [
       "0.004"
      ],
      "text/plain": [
       "[1] 0.004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2=qda(train_Y~.,data=as.data.frame(new_train_X))\n",
    "qda.pred=predict(cm2 ,newdata=as.data.frame(new_train_X))\n",
    "table3=table(qda.pred$class,train_Y)\n",
    "table3\n",
    "1-sum(diag(table3))/sum(table3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test classification error will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   test_Y\n",
       "      0   1   2   3   4   5   6   7   8   9\n",
       "  0 289   0   0   1   1   0   1   0   3   0\n",
       "  1   0 278   0   0   0   0   0   0   0   0\n",
       "  2   5   6 271  10   2   0   2   6   5   3\n",
       "  3   1   0   1 296   0  13   0   4   9   4\n",
       "  4   0   1   2   1 261   0   0   8   0  17\n",
       "  5   0   0   0   5   0 257   5   2   2   1\n",
       "  6   0   0   0   0   0   0 292   0   0   0\n",
       "  7   0   0   1   1   0   0   0 279   0   3\n",
       "  8   2  29   6   3   0   6   4   7 293   9\n",
       "  9   0   0   0   0   3   0   0   7   1 281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0676666666666667"
      ],
      "text/latex": [
       "0.0676666666666667"
      ],
      "text/markdown": [
       "0.0676666666666667"
      ],
      "text/plain": [
       "[1] 0.06766667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.pred.test=predict(cm2 ,newdata=as.data.frame(new_test_X))\n",
    "table4=table(qda.pred.test$class,test_Y)\n",
    "table4\n",
    "1-sum(diag(table4))/sum(table4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d). \n",
    "Table of training and test errors will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>1</th><th scope=col>2</th><th scope=col>3</th><th scope=col>4</th><th scope=col>5</th><th scope=col>6</th><th scope=col>7</th><th scope=col>8</th><th scope=col>9</th><th scope=col>10</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>train_error</th><td>0.00000000</td><td>0.02833333</td><td>0.034     </td><td>0.03600000</td><td>0.04266667</td><td>0.04733333</td><td>0.048     </td><td>0.05166667</td><td>0.05800000</td><td>0.063     </td></tr>\n",
       "\t<tr><th scope=row>test_error</th><td>0.06933333</td><td>0.08066667</td><td>0.067     </td><td>0.06766667</td><td>0.06933333</td><td>0.07533333</td><td>0.074     </td><td>0.07833333</td><td>0.07733333</td><td>0.080     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\\\\n",
       "\\hline\n",
       "\ttrain\\_error & 0.00000000 & 0.02833333 & 0.034      & 0.03600000 & 0.04266667 & 0.04733333 & 0.048      & 0.05166667 & 0.05800000 & 0.063     \\\\\n",
       "\ttest\\_error & 0.06933333 & 0.08066667 & 0.067      & 0.06766667 & 0.06933333 & 0.07533333 & 0.074      & 0.07833333 & 0.07733333 & 0.080     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | \n",
       "|---|---|\n",
       "| train_error | 0.00000000 | 0.02833333 | 0.034      | 0.03600000 | 0.04266667 | 0.04733333 | 0.048      | 0.05166667 | 0.05800000 | 0.063      | \n",
       "| test_error | 0.06933333 | 0.08066667 | 0.067      | 0.06766667 | 0.06933333 | 0.07533333 | 0.074      | 0.07833333 | 0.07733333 | 0.080      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            1          2          3     4          5          6          7    \n",
       "train_error 0.00000000 0.02833333 0.034 0.03600000 0.04266667 0.04733333 0.048\n",
       "test_error  0.06933333 0.08066667 0.067 0.06766667 0.06933333 0.07533333 0.074\n",
       "            8          9          10   \n",
       "train_error 0.05166667 0.05800000 0.063\n",
       "test_error  0.07833333 0.07733333 0.080"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(class)\n",
    "train_error=NULL;\n",
    "test_error=NULL;\n",
    "for(i in 1:10)\n",
    "{\n",
    "  m_tmp=knn(new_train_X,new_train_X,train_Y,k=i);\n",
    "  table7=table(m_tmp,train_Y)\n",
    "  table7\n",
    "  train_error[i]=1-sum(diag(table7))/sum(table7)\n",
    "  \n",
    "  m_tmp=knn(new_train_X,new_test_X,train_Y,k=i);\n",
    "  table8=table(m_tmp,test_Y)\n",
    "  table8\n",
    "  test_error[i]=1-sum(diag(table8))/sum(table8)\n",
    "}\n",
    "knn_table=rbind(train_error,test_error);\n",
    "colnames(knn_table)=1:10\n",
    "knn_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best K value chosen by test calssification error will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "which.min(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD/AAD///89ODILAAAACXBIWXMAABJ0\nAAASdAHeZh94AAAZv0lEQVR4nO3di1baWBiA0RNAVATK+z/tSEAHWy8If84te681LbbTnEDy\nGcjNdADulkrPAPRASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBASBBA\nSBBASBBASBBASBBASBBASBBASBBASBBASBBASBAgQ0gJGnPDWh4fToEhqh6f5gipxvFpjpBq\nHJ/mCKnG8WlOzpD2DyktN+eJfDuV0ity6fFpTsaQ9sO4d2N1moiQ6EnGkNbp6bWmp2E5TkRI\n9CRjSMPpH+6GxU5IdCZjSG/t7JdLIdGZjCEt0v7t0VJI9CVjSE/p4fxol5ZCois5d3+v3+vZ\n/HBuUukVufT4NCfrAdnt6u3R7kFI9MSZDTWOT3OEVOP4NEdINY5Pc4RU4/g0R0g1jk9zsp7Z\ncPWluaVX5NLj05ysB2QLhbT5YpCvRxESv5Tzrd32dOL3lEN8ZvHF1IREnLwHZNN66iE+m9jv\npyYkfinvzoantP16svfd2+hrQmJ6/e+1O4eZ0n5xvDp3s0ppWJ/+4vjfbpWGxynHZxZmFNJr\nQevD42mLtz68hTRe//53SULil5oJ6fb7XZ7+MKXlfvzt+XB4Hv/oFNLrnz6lxc/jw3eaCemO\niZ1Devnrj04hvbz/H1ONzxyUCinjcaS3kM5f7jaPy4uQPp0ZIfFLswtp+f4WUEjEmdFbu/GL\nh7R42uyERLC5hTT+JiSizSKk3eEipJfD1mckomUN6eVxdbpr8frl+/8x+Fy7NLzHsj7vJn8R\nEpEyhrRfXBzv+f701dAV+WVxEdLheCP/l83xHAchESdjSOs0PJ9Otdtthu9PXy29Ipcen+Zk\nDGm4OGN1e9xIxA8RpfT4NCdjSB/eQLlClq7YItU4Ps3J+xlpsxsf+YxEb3Lu/l5e7LVb7L/7\nP0uvyKXHpzl5jyOtx+NIw+ox53GkG5Qen+bM4MyGBsenOUKqcXyaI6Qax6c5cwjpixtEfvNX\nQuKXZhDSVzeI/OavhMQvzSCk7+6oKiRiCGny8ZmD/kN6v0vX0yINT+MfbZYpLTcXfzXl+MzC\nfEJavV8Hdf6xGE9CIkwzIf25zmcTG6e2Od4Kcr9Mm/PZs8/Hu0J6a0eQZkK6Y2Lj1FbpeHbf\n/nRp7ObDX008PnMwm5Aubmq8Tmm13f7/VxOPzxzMMaTD4/HO+cNOSISZUUiXf7ZZL3xGItBs\nQlqlzb9/LCSCzCKk43W5z2nYHvd8r44nBj2/77XbTT8+czCDkE43iDxfn3v8ZPT8fo/I819N\nOz5zMIOQTjeIHM9sSA/jFmg8s+Hl4q8mHZ85mEFIDY5Pc4RU4/g0R0g1jk9zhFTj+DRHSDWO\nT3OEVOP4NEdINY5Pc4RU4/g0R0g1jk9zhFTj+DRHSDWOT3OEVOP4NEdINY5Pc4RU4/g0R0g1\njk9zhFTj+DRHSDWOT3MqDam06Z8ifak0pOmHgEhCggBCggBCggBCggBCggBCggBCggBCggBC\nggBCggBCggBCggBCggBCggBCggBCggBCggBCggBZQ3p5XI13RFitX6YaAorIGNJ+cXF3keUk\nQ0AhGUNap+F5Oz7abYa0nmIIKCRjSEPavj/epmGKIaCQjCF9uFvc97eOExKNsUWCAHk/I212\n4yOfkehNzt3fy4u9dov9JENAGXmPI63H40jD6tFxJPrizAYIICQIICQIICQIICQIkPXMhqt/\nKJ6QaEzGkJ6ERLdyvrXbDt9fPBEwBJSR9TPS9vsTgyKGgCLy7mx4ujhv9Z/J+qnitMteOwgg\nJAggJAggJAhQKiTHkeiKkCCAt3YQQEgQQEgQwL2/IYB7f0MA9/6GAO60CgHc+xsC2CJBAPf+\nhgDu/Q0B3PsbAjizAQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQII\nCQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQII\nCQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQII\nCQIICQIICQIICQLkDGn3kIbHw+FpkYb1RENAGRlD2g/p1dPj8de0nGQIKCRjSOv0uh1aD+lh\nf9iPj+OHgEIyhjSM/zCl/fjbMMUQUEjGkFL6/9e334KHgEIKbJGOv+5tkehKgc9I6/35cfwQ\nUIi9dhDAcSQI4MwGCCAkCJA1pJfH1fgBabV+mWoIKCLnzoZF+p+dDXQl6+7v4Xk7PtptBru/\n6UrWA7Lb98dbB2TpSvZThD77ImyIq/2ZegBmZpZbpD9/lESsvJ+RNrvxUeHPSH/ef4EgOXd/\nLy/22i32/0z20q1DXOPPh9/gWn/+fL3S5D2OtB6PIw2rx3LHkf5/Lb55VeCDP6Pv/o+5ndnw\n58sv4DM/JnQyr5D+fkWUxNd+3gxdmFVI/74oSuIzv0nopFRIJY4jffbKKIkPfrUZujCfkL54\ndZTE2Y0Jnczmrd2Xr5CSuK+h0VxC+uZVUlLF/ryZdoD7pzOPkL5/pRxQqtOHNfzPB2HTD1v0\ns7iw78dXS0nV+X4dvzOrCTZyM7iw75pXTEk1+e1a/puspnqf2P+Ffde9akqqxd3r+VdZTftZ\nq/vLKK595ZRUgQnW9ODPVV/q/MK+X7x8Sipr+nV9Un1vkX73TjtoUH6v7YiOer6w77cLp/Vl\n2ajGN0Vn9VzYFzLEpVv2ikaMyy90EdFRvxf23bSAOlmqbehjU3TW65kNty6ifpZs5XqK6KjT\nkG5fSH0t3jp1tSk66zOkexZTd4u4Mh1GdNRjSHcuqS6X8/WmPHzZ46borMOQ7l5UvS7ra7yv\n6JOcax0yoTp1F1LE0up5gX/nq1X9/qj6juiot5CivnuGTKYpV67rv4+q803RWWchhS2xGSz6\nD25a16+IahYRHXUVUuRCm8nyH0Ws7Z9ENY9N0VlPIcUutbmsAxOs7VmuW6hMPyHFX8kSPL0q\nzWx1n043IU2wQnS/js1tqzGlXkKaZI3oezVTUaQ+Qppqneh3XbMxCtZFSBOuE12ubiqK10NI\nk64V/a1yKppC+yFNvV70tdrZGE2k+ZCmXy/6WfNUNJ3GQ8qyZnSy9qloSm2HlGnV6GANtDGa\nWNMhZVs3Gl8JVTS9hkPKuXa0vCa2PO/taDekzKtHo2ujjVEmrYaUf/1ocYVUUTaNhlRiBWlt\npbQxyqnNkMqsIS2tlyrKrMWQiq0jzaybKsquwZAKriRNrJ82RiW0F1LRtaT6VVRFhbQWUun1\npPT436t77rrWWEgVrCgVzMInZni7kbo0FlINalpdM/2kYX4kpN8rv9bqpzpCukGx3e/6qZaQ\nbpH7PD/9VE9IN8myTtsANURIt5nyxkX6aZCQbhR/h2T9tExIN7tzjf/zl5iZohAh3e66df/v\nYITTJSHd4UMMgpk1Id1DMJwJCQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQIICQII\nCQLkDGm/Hl5/fVyktHyeaAgoI2NIuyGlw/71l6PlJENAIRlDekir/esvD7vXph7SeoohoJCM\nIaW0P//y+i4vDVMMAYVkDen1lyFdfBE+BEzpm7U261u77eHwePzluEX69kOSkKhO+vabf8aQ\ntmlYbw+r4bWkzSJtphgCpvF9RYe8u7835z12R4/TDAHxfqzocHdIq293vv3j+WFxrGj1uAuf\nK5jENRUd7g7pukHuGgKKubKiw90hLU57s6MJieLS9RUd7g5pv1q+XP8vXx5X4wek1fqHfyQk\nyvpVROM/uGGMj+O9+fHf7RcX/7dThKjWrys6ZA1pnYbn8SDSYbcZnCJEnW6p6JB19/dwOhY7\n2jpFiArdWNEh/ylCn34RNgTc7vaKDgEhPS+Pew9+uL5oZItEve6q6HB/SMurdh6MXj8jbU4H\nYn1Goir3VnS4O6Sn1zgO48k/Tz//w+XFronFP8efUvrNngsIErO63X1A9vR2bZsWV/zLl/V4\nHGlYPTqORBXCvmlHnSIUuxEREhlEvvUJ2yJ9u/PgniFgAtEfIHJ+RrptCIg2wafwjHvtPk7E\ncSTKmGZf1v3HkVbXHkf6OBEhUcBke4TdaZXZmPK4St4rZG8ZAiJMfHTSFbLMwPTH+LNeIevC\nPkrIcaZMxitkXdhHAZlOOHNhHz3LdtpmxpBcRkFeOc9+dmEfncp7DUHG3d+2SOST+1KcjLu/\nXdhHJgWuaMu5+/v7C/vunCs4K3JdaN4bRLqwj4mVurw64167G4eAq5W7SYGQ6EXRe304+5s+\nFL5jjpDoQPkbT90d0mZ1fA6rH35y2F1DwLeKV3QIutT89c+G0JIqeGFoRQ0ZBdz8ZLk/PpGn\n9BA2Swchca3y7+nO7gxpSPvTdwR77civlooOIacICYkSqtkYjQJOETo+n+tuWXzTEPCJqio6\nRH1GcoNIcqprYzS6d6/d6sYbRP5iCPigvooOQceRbrhB5G+GgHcVboxGzmygIZVWdBASDak3\nIyHRilrf050JiRbUXdFBSDSg8o3RSEhUroGKDkKiau38hHshUal2IjoSEhVqK6IjIVGZ9iI6\nEhIVaTOiIyFRiXYjOhIS5YXfGDE/IVFW+w2NhEQ5nUR0JCTK6CiiIyGRX2cRHQmJrDrYr/Ap\nIZFNpw2NhEQWPUd0JCQm13tER0JiUnOI6EhITGYuER0JiUDpg9Jzk5OQuEH6Qun5KkdIfEMw\n1xISHwnmJkLignZuJSTObIHuISSORHQnIaGiAEKaOxWFENKsqSiKkGbLzoVIQponEQUT0gyp\nKJ6Q5kZFkxDSnPhYNBkhzYaIpiSkeVDRxIQ0AyqanpA652NRHkVC+nHRWvQxRJSNkLqlopwy\nhvSLq5WtAfdSUWYZQ3oZhJSHivLL+dZuv0rL3TgFb+0mY+dCGXk/Iz2n9HwQ0mREVEzmnQ27\nZVrthTQJFZWUfa/dYxo2QoqnorLy7/7eLn7+1mml+CUZlVbiONKDkEJ5T1cBpwi1TkVVyBrS\ny+NqPIS0Wr9MNcTM2BjVImNI+8XF4djlJEPMjIrqkTGkdRqet+Oj3WZI6ymGmBUZ1SRjSEPa\nvj/epmGKIebDe7rKZD1p9asvwoaYCxVVxxapPTKqUN7PSJvxnFWfke7gPV2dcu7+Xl7stVvs\n/5msnxT3M69MrfIeR1qPx5GG1aPjSLeQUb2c2dAK2+mqCakNKqqckBpgY1S/UiE5jnQ1FbVA\nSJWTURu8tauZ93TNEFK9VNQQIdVKRk1xYV+VvKdrjQv7KqSi9riwrzoyapHLKOriPV2jXNhX\nExU1yxapGjZGLXNhXyVU1LZ6LuwLGaJVMmqdC/tKc0VwF5zZUIqr6rsipNwE1CUh5SKgrglp\nagKaBSFNRUCzIqRoApolIUUR0KwJ6V4C4iCkuwiIN0K6lYa4IKTbqIgPhHQDGyP+JqTfUhGf\nENKvqIjPCekXVMRXhHQtGyO+IaSrqIjvCekKKuInQvqJjRFXENK3VMR1hPQ1FXE1IX1FRfyC\nkD6fARnxK0L6ZHQV8VtC+ntoFXEDIX0cWEXcREgXo8qIWwnpbUgVcQchnQZUEXcRko0RAWYf\nkoqIMO+QVESQOYekIsLMNiQbIyLNNCQVEWueIcmIYEKCALMMSUdEExIEmGNIOiKckCDADEPS\nEfGEBAHmF5KOmMDsQtIRUxASBJhbSDpiEkKCADMLSUdMQ0gQYF4h6YiJCAkCzCokHTGVOYWk\nIyaTM6T9Q0rLzXki305FSDQmY0j7IR2tThPJH5KOmE7GkNbp6bWmp2E5TkRI9CRjSMPpH+6G\nxa5ESDpiQhlDemtnv1wKic5kDGmR9m+PlvlD0hFTyhjSU3o4P9qlpZDoSs7d3+v3ejY/3Hk7\nfq3XEZPKekB2u3p7tHvIG5KOmNZMzmwQEtOaR0g6YmJZQ3p5XJ1Obli/TDVEnunBX3KeIrRI\n/1tOMkSeycE/sp4iNDxvx0e7zZDWUwyRZ3Lwj6ynCG3fH2/TMMUQOaYGnyhwitC/X4QNkWNq\n8IkZbJF0xPTyfkba7MZHeT8jCYnp5dz9vbzYa7fY//236dKtQ3xCR2SQ9zjSejyONKwe8x1H\n0hE5dH9mg5DIofeQdEQWQoIApULKdBxJR+QhJAjQ91s7HZGJkCBA1yHpiFx6vrBPR2TT84V9\nQiKbji/s0xH5dHwZhZDIp98L+3RERv1ukYRERt1e2Kcjcqrnwr6QIUInAVfr9cI+HZFVp2c2\n6Ii8hAQB+gxJR2QmJAjQZUg6IjchQYAeQ9IR2QkJAnQYko7Ir7+QdEQBQoIA3YWkI0oQEgTo\nLSQdUYSQIEBnIemIMoQEAfoKSUcU0lVIOqIUIUGAnkLSEcUICQJ0FJKOKEdIEKCfkHREQUKC\nAN2EpCNKqnOV/f0QOqIoIUGATkLSEWUJCQL0EZKOKExIEKCLkHREaUKCAD2EpCOK6yAkHVGe\nkCBA+yHpiAoICQI0H5KOqIGQIEDrIemIKggJAjQeko6og5AgQNsh6YhKNB2SjqiFkCBAyyHp\niGoICQI0HJKOqIeQIEC7IemIiggJAmQN6eVxlY5W65e7h9ARNckY0n6R/re8cwgdUZWMIa3T\n8LwdH+02Q1rfN4SQqErGkIa0fX+8TcNdQ+iIumQMKaWvvvj9EEKiLm1ukXREZfJ+Rtrsxkd3\nf0YSEpXJuft7ebHXbrG/YwgdUZu8x5HW43GkYfV433EkIVGbFs9s0BHVaTAkHVGfBk8REhL1\nae8UIR1RofZOERISFWrugKyOqFFzpwgJiRq1tkXSEVVq7RQhIVGlek4RSpfCx4ZJNXmKENSm\nwTMboD5CggBCggClQrrzUnOoi5AggLd2EEBIEEBIEKDBC/ugPu1d2AcVau/CPqhQa5dRQJWa\nu7APamSLBAFau7APqlTPhX0hQ0AZLuyDAM5sgABCggBCggBCggBCggBCggBCggBCggBCggBC\nggBCggBCggBCggBCggBCggBCggBCggBCggBCggBCggBCggBCggBCggBCggBCggBCggBCggCV\nhgSNuWEtjw8nu7qeg7n5WsdzU9dTu01dz8HcfK3juanrqd2mrudgbr7W8dzU9dRuU9dzMDdf\n63hu6npqt6nrOZibr3U8N3U9tdvU9RzMzdc6npu6ntpt6noO5uZrHc9NXU/tNnU9B3PztY7n\npq6ndpu6noO5+VrHc1PXU7tNXc/B3Hyt47mp66ndpq7nYG6+1vHc1PXUblPXczA3X+t4bup6\natAoIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUEAIUGA5kN6WqRh\nvS89Fxde6nlJtw8pPexKz8XZfj1Us6Se3pZR3DzVs9Rvsx5/eMBQx/I52g/VvKSbml6b3XCa\nmxq63r79uInlOE+LiGlWs9Rvs00P++M3mIfSM/JudcvPBJnGMGwP+1Val56P0cM4H+saltR2\nOC+jl/T6Cr1+9RIw0WqW+m1Wp/mvZ+V9vumH60zieVx192koPSOjVM2SekrL81ys0+ZwfJ0e\nA6Za/nlFqGDxnOzeF1J5D2lbehYunN/xVpD16/eX8zJapeMbzW1aRUw1YBrF7dOy9CycLdOu\nmpAW6fA4jG99a/B4fmsX8d3/Ptu/N48hS6yWpX6Xp3ETXYHH9FzP1jGl1fjxvvR8nD0d9zYM\nT6VnYySkT+2GiG1zgPFNQkUhHXc2PFSwDRg9jnvI6pgZIX1mP9Tyxm5x3NVcUUjHz0i7mL27\nd3s6vrV7zbqKTZKQPrOsY005fro/vsOsKKTL30pbpOOHtX0dWZ9fk0FI/9stljUc4zu656fL\nT6CuQwNVZf1hr93OXrvD8eh9Le/rqgvpcdxA7ip5gU7f/Ss5qnVeQqdXaBNyyLqOZX6zWlaT\nC5VkNH462h8/lTyXnpHROh3PaVvXcZ6FMxv+9lDVNmBUz7yc9pPV8p1mWdHcvC2jRdw8VbPU\nb1PXm6lRRfOyWaahii3AaDzTuvRMnLwto33cPNWz1KFhQoIAQoIAQoIAQoIAQoIAQoIAQoIA\nQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIAQoIA\nQoIAQoIAQoIAQoIAQoIAQoIAQoIAQmrS6UfObVIdP5IVITVqDGk/VPIjWRFSo8aQlmkoPR+8\nEVKTjiE9pbQrPR+8EVKTXkPaprQpPRu8E1KTXkNa2NFQEyE1KaWHlPal54L/CalJ6WhVei74\nn5CalNLwmNJz6dngnZCadNzR8GCvXUWE1KTxONLC8dh6CKlJY0i7lB5LzwhnQmrS6Vy755S2\npeeEEyE16RTS68ekReEZ4UxITTqH9Pox6aHsjHAmJAggJAggJAggJAggJAggJAggJAggJAgg\nJAggJAggJAggJAggJAggJAggJAggJAggJAggJAggJAggJAggJAggJAggJAggJAggJAggJAgg\nJAggJAggJAggJAggJAjwH6Blz9nvjdJDAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot((1:10),train_error,type=\"l\",ylim=c(-0.005,0.12),xlab=\"K\",ylab=\"error\")\n",
    "lines((1:10),test_error,col=\"red\")\n",
    "legend(\"topleft\",c(\"train\",\"test\"),col=c(\"black\",\"red\"),lty=c(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e). \n",
    "Fit multiple logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'doParallel' was built under R version 3.4.3\"Loading required package: iterators\n",
      "Loading required package: parallel\n"
     ]
    }
   ],
   "source": [
    "library(doParallel)\n",
    "cl <- makePSOCKcluster(4) # number of cores to use\n",
    "registerDoParallel(cl)\n",
    "cm3=cv.glmnet(new_train_X,(train_Y),family=\"multinomial\",parallel=TRUE);\n",
    "stopCluster(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training classification error will be   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            train_Y\n",
       "mul_log_pred   0   1   2   3   4   5   6   7   8   9\n",
       "           0 297   0   4   0   0   2   0   0   0   3\n",
       "           1   0 346   2   1   2   2   0   2   3   2\n",
       "           2   1   1 266   2   0   3   1   4   4   0\n",
       "           3   0   0   3 291   0   7   0   0   6   4\n",
       "           4   0   1   3   0 278   1   3   1   0  10\n",
       "           5   1   0   0  10   0 237   5   1   7   1\n",
       "           6   4   1   4   2   4   5 286   0   2   0\n",
       "           7   0   1   4   2   0   1   0 283   1   8\n",
       "           8   2   1   1   7   2   4   1   1 266   2\n",
       "           9   1   0   4   4   9   2   0   8   4 255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0649999999999999"
      ],
      "text/latex": [
       "0.0649999999999999"
      ],
      "text/markdown": [
       "0.0649999999999999"
      ],
      "text/plain": [
       "[1] 0.065"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mul_log_pred=predict(cm3,newx=new_train_X,s=\"lambda.min\",type=\"class\")\n",
    "table9=table(mul_log_pred,train_Y);\n",
    "table9\n",
    "1-sum(diag(table9))/sum(table9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test classification error will be   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 test_Y\n",
       "mul_log_pred_test   0   1   2   3   4   5   6   7   8   9\n",
       "                0 281   0   3   2   0   5   1   0   3   5\n",
       "                1   0 302   2   2   1   2   1   5   7   2\n",
       "                2   3   0 231  13   0   0   1   6   7   2\n",
       "                3   2   2   3 267   1  16   0   4  13   6\n",
       "                4   1   0   5   0 245   8   0   4   0  15\n",
       "                5   6   4   4  22   0 232   0   1   7   2\n",
       "                6   2   0  12   0   6   3 298   0   2   0\n",
       "                7   1   1  13   4   1   1   1 277   1  11\n",
       "                8   1   5   6   5   2   7   2   2 268   0\n",
       "                9   0   0   2   2  11   2   0  14   5 275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.108"
      ],
      "text/latex": [
       "0.108"
      ],
      "text/markdown": [
       "0.108"
      ],
      "text/plain": [
       "[1] 0.108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mul_log_pred_test=predict(cm3,newx=new_test_X,s=\"lambda.min\",type=\"class\")\n",
    "table10=table(mul_log_pred_test,test_Y);\n",
    "table10\n",
    "1-sum(diag(table10))/sum(table10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f). \n",
    "knn with $k=3$ has the lowest test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "### (a). \n",
    "The figure of accuracy will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nCPAfE1M4OMzpQsoAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heart=read.csv(\"./Data/heart/heart.csv\",header = T)\n",
    "heart=na.omit(heart)\n",
    "mt1=glm(chd~.,data=heart,family = \"binomial\")\n",
    "pmt1=predict(mt1,type=\"response\",newdata = heart)\n",
    "\n",
    "accu_re<-function(thes)\n",
    "{\n",
    "  table_tmp=table(pmt1>thes,heart$chd)\n",
    "  return(sum(diag(table_tmp))/sum(table_tmp))\n",
    "}\n",
    "acc_set=sapply(0.01*(1:90),accu_re)\n",
    "plot(0.01*(1:90),acc_set,type=\"l\",xlab=\"threshold\",ylab=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threhold chosen by maximize accuracy will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.57"
      ],
      "text/latex": [
       "0.57"
      ],
      "text/markdown": [
       "0.57"
      ],
      "text/plain": [
       "[1] 0.57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestthe1=0.01*(1:90)[which.max(acc_set)]\n",
    "bestthe1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  correponding confusion matrix will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \n",
       "          0   1\n",
       "  FALSE 274  89\n",
       "  TRUE   28  71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(pmt1>bestthe1,heart$chd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "The ROC curve will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nEPAPVEbz6obOpNMAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sen_spec_re<-function(thes)\n",
    "{\n",
    "  table_tmp=table(pmt1>thes,heart$chd)\n",
    "  return(diag(table_tmp)/colSums(table_tmp))\n",
    "}\n",
    "sen_spec_set=sapply(0.01*(1:90),sen_spec_re)\n",
    "row.names(sen_spec_set)=c(\"specificity\",\"sensetivity\")\n",
    "colnames(sen_spec_set)=0.01*(1:90)\n",
    "plot(1-sen_spec_set[1,],sen_spec_set[2,],type=\"l\",xlab=\"1-specificity\",ylab=\"sensetivity\")\n",
    "abline(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threhold chosen by maximize accuracy will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.32"
      ],
      "text/latex": [
       "0.32"
      ],
      "text/markdown": [
       "0.32"
      ],
      "text/plain": [
       "[1] 0.32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestthe2=0.01*(1:90)[which.max(colSums(sen_spec_set))];\n",
    "bestthe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  correponding confusion matrix will be "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c). \n",
    "(b) is a better approach, because it has consider the proportion of the label."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
